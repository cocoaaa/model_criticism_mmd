{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-1: features in independent\n",
    "\n",
    "Setting. The data has 3 features. Only the 1st feature has significant variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from model_criticism_mmd import ModelTrainerTorchBackend\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "size = 1000\n",
    "n_epoch = 500\n",
    "batch_size = 200\n",
    "\n",
    "x_1st_dim = numpy.random.normal(loc=1.0, scale=0.0, size=size)\n",
    "y_1st_dim = numpy.random.normal(loc=1.0, scale=50.0, size=size)\n",
    "\n",
    "x_2_and_3_dim = numpy.random.normal(loc=10.0, scale=0.2, size=(size, 2))\n",
    "y_2_and_3_dim = numpy.random.normal(loc=10.0, scale=0.2, size=(size, 2))\n",
    "\n",
    "x = numpy.concatenate([numpy.reshape(x_1st_dim, (size, 1)), x_2_and_3_dim], axis=1)\n",
    "y = numpy.concatenate([numpy.reshape(y_1st_dim, (size, 1)), y_2_and_3_dim], axis=1)\n",
    "\n",
    "x_train = x[:800]\n",
    "y_train = y[:800]\n",
    "x_val = x[800:]\n",
    "y_val = y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dim. mean(x)=1.0 mean(y)=2.5248548771197292 var(x)=0.0 var(y)=2302.8121458816827\n",
      "2 dim. mean(x)=10.0025778700585 mean(y)=9.999656248911283 var(x)=0.04029090218532031 var(y)=0.03809763318620526\n",
      "3 dim. mean(x)=9.986457221298988 mean(y)=9.99377833695908 var(x)=0.038718311478458486 var(y)=0.03903903336901691\n"
     ]
    }
   ],
   "source": [
    "for n_dim in [0, 1, 2]:\n",
    "    print(f'{n_dim+1} dim. mean(x)={x[:,n_dim].mean()} mean(y)={y[:,n_dim].mean()} var(x)={x[:,n_dim].var()} var(y)={y[:,n_dim].var()}')\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "input data N(sample-size)=800, N(dimension)=3\n",
      "Getting median initial sigma value...\n",
      "initial sigma by median-heuristics 5.77\n",
      "Validation at 0. MMD^2 = 0.570378449068937, obj-value = [-2.55274451] at sigma = [5.77303402]\n",
      "[before optimization] sigma value = [5.77303402]\n",
      "     5: avg train MMD^2 0.895900140730819 obj [-3.33088924],  avg val MMD^2 0.8683895713933495  obj [-3.30440728]  elapsed: 0.0 sigma: [5.77303402]\n",
      "    25: avg train MMD^2 0.9627276664674961 obj [-3.82855203],  avg val MMD^2 0.9505839835250025  obj [-3.73772921]  elapsed: 0.0 sigma: [5.77303402]\n",
      "    50: avg train MMD^2 0.9744422481624296 obj [-4.01698482],  avg val MMD^2 0.9658202623062823  obj [-3.92844643]  elapsed: 0.0 sigma: [5.77303402]\n",
      "   100: avg train MMD^2 0.985418448491003 obj [-4.25528742],  avg val MMD^2 0.979647658510809  obj [-4.20251889]  elapsed: 0.0 sigma: [5.77303402]\n",
      "   200: avg train MMD^2 0.9927786826435757 obj [-4.97156057],  avg val MMD^2 0.992474272839823  obj [-4.58691875]  elapsed: 0.0 sigma: [5.77303402]\n",
      "   300: avg train MMD^2 0.995630839894702 obj [-4.65991243],  avg val MMD^2 0.9985601109284832  obj [-4.88013027]  elapsed: 0.0 sigma: [5.77303402]\n",
      "   400: avg train MMD^2 0.9973262625993855 obj [-5.24870989],  avg val MMD^2 1.001402938890547  obj [-5.08938782]  elapsed: 0.0 sigma: [5.77303402]\n",
      "   500: avg train MMD^2 0.9983965711860483 obj [-4.91196657],  avg val MMD^2 1.003120100546431  obj [-5.28261272]  elapsed: 0.0 sigma: [5.77303402]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([18.80152   ,  0.47757486,  0.02871666], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainerTorchBackend()\n",
    "trained_obj = trainer.train(x_train, y_train, num_epochs=500, batchsize=200, opt_sigma=False, x_val=x_val, y_val=y_val)\n",
    "trained_obj.scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, only the 1st feature has a huge weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case-2: dependency between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from model_criticism_mmd import ModelTrainerTorchBackend\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "size = 1000\n",
    "n_epoch = 500\n",
    "batch_size = 200\n",
    "\n",
    "x_1st_dim = numpy.random.normal(loc=1.0, scale=0.0, size=size)\n",
    "y_1st_dim = numpy.random.normal(loc=1.0, scale=50.0, size=size)\n",
    "\n",
    "x_2_dim = x_1st_dim + numpy.full(size, 5)\n",
    "y_2_dim = y_1st_dim + numpy.full(size, 5)\n",
    "\n",
    "x_3_dim = numpy.random.normal(loc=10.0, scale=0.2, size=size)\n",
    "y_3_dim = numpy.random.normal(loc=10.0, scale=0.2, size=size)\n",
    "\n",
    "x = numpy.concatenate([numpy.reshape(x_1st_dim, (size, 1)), \n",
    "                       numpy.reshape(x_2_dim, (size, 1)), \n",
    "                       numpy.reshape(x_3_dim, (size, 1))], axis=1)\n",
    "y = numpy.concatenate([numpy.reshape(y_1st_dim, (size, 1)), \n",
    "                       numpy.reshape(y_2_dim, (size, 1)), \n",
    "                       numpy.reshape(y_3_dim, (size, 1))], axis=1)\n",
    "\n",
    "x_train = x[:800]\n",
    "y_train = y[:800]\n",
    "x_val = x[800:]\n",
    "y_val = y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dim. mean(x)=1.0 mean(y)=2.1910425430340887 var(x)=0.0 var(y)=2447.067672309139\n",
      "2 dim. mean(x)=6.0 mean(y)=7.191042543034089 var(x)=0.0 var(y)=2447.067672309139\n",
      "3 dim. mean(x)=9.995718941316799 mean(y)=9.998072262749757 var(x)=0.03785323101657011 var(y)=0.04067125114367236\n"
     ]
    }
   ],
   "source": [
    "for n_dim in [0, 1, 2]:\n",
    "    print(f'{n_dim+1} dim. mean(x)={x[:,n_dim].mean()} mean(y)={y[:,n_dim].mean()} var(x)={x[:,n_dim].var()} var(y)={y[:,n_dim].var()}')\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "input data N(sample-size)=800, N(dimension)=3\n",
      "Getting median initial sigma value...\n",
      "initial sigma by median-heuristics 21.6\n",
      "Validation at 0. MMD^2 = 0.5044419288530552, obj-value = [-2.47590033] at sigma = [21.55086058]\n",
      "[before optimization] sigma value = [21.55086058]\n",
      "     5: avg train MMD^2 0.652114011931433 obj [-2.70397245],  avg val MMD^2 0.6087357732319278  obj [-2.64780603]  elapsed: 0.0 sigma: [21.55086058]\n",
      "    25: avg train MMD^2 0.8259701632690684 obj [-3.11592114],  avg val MMD^2 0.7848342584701159  obj [-3.0577062]  elapsed: 0.0 sigma: [21.55086058]\n",
      "    50: avg train MMD^2 0.8788659961303843 obj [-3.32156548],  avg val MMD^2 0.849867934575372  obj [-3.23360533]  elapsed: 0.0 sigma: [21.55086058]\n",
      "   100: avg train MMD^2 0.9186596405940634 obj [-3.51536248],  avg val MMD^2 0.8941404974608519  obj [-3.37122516]  elapsed: 0.0 sigma: [21.55086058]\n",
      "   200: avg train MMD^2 0.9481940664973482 obj [-3.72848956],  avg val MMD^2 0.919975789315546  obj [-3.50063765]  elapsed: 0.0 sigma: [21.55086058]\n",
      "   300: avg train MMD^2 0.9614011109338887 obj [-3.86002514],  avg val MMD^2 0.9308582256624698  obj [-3.58390021]  elapsed: 0.0 sigma: [21.55086058]\n",
      "   400: avg train MMD^2 0.9679673054002143 obj [-3.92850715],  avg val MMD^2 0.937887262774574  obj [-3.65256578]  elapsed: 0.0 sigma: [21.55086058]\n",
      "   500: avg train MMD^2 0.973517158458369 obj [-4.06462727],  avg val MMD^2 0.9430646548401108  obj [-3.71305232]  elapsed: 0.0 sigma: [21.55086058]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9.71038   , 12.313313  ,  0.16370258], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainerTorchBackend()\n",
    "trained_obj = trainer.train(x_train, y_train,num_epochs=500, batchsize=200, opt_sigma=False, x_val=x_val, y_val=y_val)\n",
    "trained_obj.scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that a weight on both 1st dimenstion and 2nd dimenstion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
